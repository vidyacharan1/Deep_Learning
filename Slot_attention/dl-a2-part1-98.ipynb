{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7764ce77",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-05T12:48:38.625648Z",
     "iopub.status.busy": "2024-05-05T12:48:38.625270Z",
     "iopub.status.idle": "2024-05-05T12:48:45.443102Z",
     "shell.execute_reply": "2024-05-05T12:48:45.442322Z"
    },
    "papermill": {
     "duration": 6.824635,
     "end_time": "2024-05-05T12:48:45.445471",
     "exception": false,
     "start_time": "2024-05-05T12:48:38.620836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class SlotAttentionModule(nn.Module):\n",
    "    def __init__(self, num_slots, num_iters, slot_size, mlp_hidden_dim, eps=1e-8):\n",
    "        super(SlotAttentionModule, self).__init__()\n",
    "        self.num_slots = num_slots\n",
    "        self.num_iters = num_iters\n",
    "        self.slot_size = slot_size\n",
    "        self.eps = eps\n",
    "        self.mlp_hidden_dim = mlp_hidden_dim\n",
    "\n",
    "        self.input_norm = nn.LayerNorm(slot_size)\n",
    "        self.mu_slot = nn.Parameter(torch.randn(1, 1, slot_size))\n",
    "        self.sigma_slot = nn.Parameter(torch.randn(1, 1, slot_size))\n",
    "        self.k_proj = nn.Linear(slot_size, slot_size, bias=False)\n",
    "        self.q_proj = nn.Linear(slot_size, slot_size, bias=False)\n",
    "        self.v_proj = nn.Linear(slot_size, slot_size, bias=False)\n",
    "        self.slots_norm = nn.LayerNorm(slot_size)\n",
    "        self.gru = nn.GRUCell(slot_size, slot_size)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(slot_size, mlp_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_hidden_dim, slot_size)\n",
    "        )\n",
    "        self.mlp_norm = nn.LayerNorm(slot_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        inputs = self.input_norm(x)\n",
    "        k = self.k_proj(inputs)\n",
    "        v = self.v_proj(inputs)\n",
    "        slots = self.mu_slot + torch.exp(self.sigma_slot) * torch.randn((x.size(0), self.num_slots, self.slot_size), device=x.device)\n",
    "\n",
    "        for _ in range(self.num_iters):\n",
    "            slots_prev = slots\n",
    "            slots = self.slots_norm(slots)\n",
    "            q = self.q_proj(slots)\n",
    "            q = q * torch.sqrt(torch.tensor(1/self.slot_size, dtype=torch.float32, device=x.device))\n",
    "            attn = F.softmax(torch.bmm(k, q.transpose(1, 2)), dim=-1)\n",
    "            attn = (attn + self.eps) / torch.sum(attn, dim=-2, keepdim=True)\n",
    "            # print(attn.shape, v.shape)\n",
    "            attn_sh = attn.permute(0, 2, 1)\n",
    "            updates = torch.bmm(attn_sh, v)\n",
    "            # print(updates.shape, slots_prev.shape)\n",
    "            upd = updates.reshape(-1,self.slot_size)\n",
    "            sl_pr = slots_prev.reshape(-1,self.slot_size)\n",
    "            slots = self.gru(upd, sl_pr)\n",
    "            # print(slots.shape, slots_prev.shape)\n",
    "            slots_new = slots.reshape(-1, self.num_slots, self.slot_size)\n",
    "            slots = slots_new + self.mlp(self.mlp_norm(slots_new))\n",
    "        return slots\n",
    "    \n",
    "# samodule = SlotAttentionModule(11, 3, 64, 128)\n",
    "# x = torch.randn(64,128*128,64)\n",
    "# y = samodule(x)\n",
    "# print(y.shape)\n",
    "\n",
    "\n",
    "def grid_embed(resolution):\n",
    "    scope = [np.linspace(0.0, 1.0, num=x) for x in resolution]\n",
    "    grid = np.meshgrid(*scope, indexing='ij', sparse=False)\n",
    "    grid = np.stack(grid, axis=-1)\n",
    "    grid = np.reshape(grid, (resolution[0], resolution[1], -1))\n",
    "    grid = np.expand_dims(grid, axis=0)\n",
    "    grid = grid.astype(np.float32)\n",
    "    # print(grid.shape)\n",
    "    return torch.cat([torch.tensor(grid), 1.0 - torch.tensor(grid)], dim=-1)\n",
    "\n",
    "# print(grid_embed((128, 128)).shape)\n",
    "\n",
    "class SlotAttentionNetwork(nn.Module):\n",
    "    def __init__(self, num_slots, num_iters, resolution):\n",
    "        super(SlotAttentionNetwork, self).__init__()\n",
    "        self.num_slots = num_slots\n",
    "        self.num_iters = num_iters\n",
    "        self.resolution = resolution\n",
    "\n",
    "        self.cnn_encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 5, padding=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(64)\n",
    "        self.dense_encode = nn.Linear(4, 64)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64)\n",
    "        )\n",
    "        self.slot_attention = SlotAttentionModule(num_slots, num_iters, 64, 128)\n",
    "        self.decoder_size = (8, 8)\n",
    "        self.dense_decode = nn.Linear(4, 64)\n",
    "        self.cnn_decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 64, 5, stride=2, padding=2, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 64, 5, stride=2, padding=2, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 64, 5, stride=2, padding=2, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 64, 5, stride=2, padding=2, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 64, 5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 4, 3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.cnn_encoder(input)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        temp = grid_embed(self.resolution).to(device)\n",
    "        # temp = temp.view(1, -1, temp.size(-1))\n",
    "        x = x + self.dense_encode(temp)\n",
    "        x = x.view(-1, x.size(1) * x.size(2), x.size(-1))\n",
    "        x = self.mlp(self.norm(x))\n",
    "        slots = self.slot_attention(x)\n",
    "        x = slots.view(-1, slots.shape[2])[:, None, None, :]\n",
    "        x = x.repeat(1, self.decoder_size[0], self.decoder_size[1], 1)\n",
    "        x = x + self.dense_decode(grid_embed(self.decoder_size).to(device))\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = self.cnn_decoder(x)\n",
    "        x = x.view(input.shape[0],11,4,128,128)\n",
    "        recons, masks = torch.split(x, (3, 1), dim=2)\n",
    "        masks = torch.sigmoid(masks)\n",
    "        combined = torch.sum(recons * masks, dim=1)\n",
    "        return recons, masks, combined, slots\n",
    "    \n",
    "# model = SlotAttentionNetwork(11, 3, (128, 128))\n",
    "# x = torch.randn(32, 3, 128, 128)\n",
    "# recons, masks, combined, slots = model(x)\n",
    "# print(recons.shape, masks.shape, combined.shape, slots.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bf9b579",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:48:45.452128Z",
     "iopub.status.busy": "2024-05-05T12:48:45.451497Z",
     "iopub.status.idle": "2024-05-05T12:48:49.579856Z",
     "shell.execute_reply": "2024-05-05T12:48:49.578701Z"
    },
    "papermill": {
     "duration": 4.134571,
     "end_time": "2024-05-05T12:48:49.582802",
     "exception": false,
     "start_time": "2024-05-05T12:48:45.448231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 64\n",
    "num_slots = 11\n",
    "num_iters = 3\n",
    "resolution = (128, 128)\n",
    "\n",
    "model = SlotAttentionNetwork(num_slots, num_iters, resolution)\n",
    "\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "# The dataset is in the folder '/kaggle/input/clevrtex-images/train'\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 0.98 ** epoch)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e2a2e71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:48:49.590511Z",
     "iopub.status.busy": "2024-05-05T12:48:49.589409Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2024-05-05T12:48:49.585716",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.035784222185611725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 0.035560254007577896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 0.033000871539115906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 0.030674703419208527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 0.03056110255420208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 0.028708886355161667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: 0.027122458443045616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: 0.023823704570531845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss: 0.02780417911708355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.028441419824957848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Loss: 0.0261697880923748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Loss: 0.023123856633901596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Loss: 0.02444463036954403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Loss: 0.024551521986722946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Loss: 0.024071794003248215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Loss: 0.026232849806547165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Loss: 0.020770413801074028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Loss: 0.021585937589406967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Loss: 0.022388508543372154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Loss: 0.02280418574810028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Loss: 0.022069770842790604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Loss: 0.022235220298171043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Loss: 0.023666050285100937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Loss: 0.01861799880862236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Loss: 0.02036302536725998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Loss: 0.022266311571002007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Loss: 0.020008407533168793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Loss: 0.02007301338016987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Loss: 0.02059587650001049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Loss: 0.021312637254595757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Loss: 0.0228983536362648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Loss: 0.020117029547691345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Loss: 0.01985171250998974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Loss: 0.01789788156747818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35, Loss: 0.01843993365764618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Loss: 0.01899407058954239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, Loss: 0.02048054151237011\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(root_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.images[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "# Define transform\n",
    "transform = transforms.Compose([transforms.CenterCrop((128, 128)), transforms.ToTensor()])\n",
    "\n",
    "# Load dataset\n",
    "data_dir = '/kaggle/input/clevrtex-images/train/train'  \n",
    "dataset = CustomDataset(data_dir, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Model training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images in dataloader:\n",
    "        images = images.to(device)\n",
    "#         print(images.shape)\n",
    "        recons, masks, combined, slots = model(images)\n",
    "#         print(combined.shape, images.shape)\n",
    "        loss = criterion(combined, images)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    print(f'Epoch: {epoch+1}, Loss: {loss.item()}')\n",
    "    \n",
    "    if (epoch % 3) == 0:\n",
    "        torch.save(model.state_dict(), f'model_checkpoint_98_{epoch}.pt')\n",
    "\n",
    "torch.save(model.state_dict(), 'model_A2_98.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ab4086",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825c7551",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4797203,
     "sourceId": 8125472,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-05T12:48:34.636638",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}